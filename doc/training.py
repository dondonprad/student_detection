# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tNmLKEurSh_KALtMZDXFz_vcc9fLBU_G
"""

!python -m ensurepip --upgrade
!python -m pip install --upgrade pip
!pip cache purge # Clear the pip package cache. This can be useful when pip is having issues resolving package dependencies.
!pip install opencv-python
!pip install mediapipe
!pip install os

!pip install csv

import mediapipe as mp
import cv2
import csv
import os

# Initialize MediaPipe Pose
mp_pose = mp.solutions.pose

# Input images and their pose labels
images = {
    "/content/drive/My Drive/desertasi/sample data/tertidur2.jpg": "Tertidur",
    "/content/drive/My Drive/desertasi/sample data/belajar.jpg": "Belajar",
    "/content/drive/My Drive/desertasi/sample data/memperhatikan.jpg": "Memperhatikan",
}

# Output CSV file
csv_file_path = "/content/drive/My Drive/desertasi/person.csv"

# Extract landmarks and save to CSV
with open(csv_file_path, mode="w", newline="") as file:
    writer = csv.writer(file)
    # Write header
    header = ["Pose"] + [f"{axis}_{idx}" for idx in range(33) for axis in ["X", "Y", "Z"]]
    writer.writerow(header)

    with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose:
        for image_path, label in images.items():
            # Read the image
            image = cv2.imread(image_path)
            if image is None:
                print(f"Error reading {image_path}")
                continue

            # Convert to RGB
            results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

            # Check if landmarks are detected
            if results.pose_world_landmarks:
                # Extract landmarks
                row = [label]
                for landmark in results.pose_world_landmarks.landmark:
                    row.extend([landmark.x, landmark.y, landmark.z])
                writer.writerow(row)
                print(f"Processed {image_path} - Pose: {label}")
                print(
                    f'NOSE coordinates: ('
                    f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE]}'
                    f'LEFT_SHOULDER coordinates: ('
                    f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]}'
                    f'RIGHT_SHOULDER coordinates: ('
                    f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]}'
                )
            else:
                print(f"No landmarks detected in {image_path}")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Load CSV data
data = pd.read_csv("/content/drive/My Drive/desertasi/person.csv")

# Separate features and labels
X = data.drop("Pose", axis=1)  # Landmark features
y = data["Pose"]              # Pose labels

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest classifier
clf = RandomForestClassifier()
clf.fit(X_train, y_train)

# Evaluate the classifier
y_pred = clf.predict(X_test)
print("Classification Report:")
print(classification_report(y_test, y_pred))
print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")

def classify_image(image_path, pose_model, classifier):
    # Read the image
    image = cv2.imread(image_path)
    if image is None:
        print(f"Error reading {image_path}")
        return

    # Convert to RGB and process with MediaPipe Pose
    results = pose_model.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

    # Check if landmarks are detected

    if results.pose_world_landmarks:
        # Extract landmarks
        landmarks = []
        for landmark in results.pose_world_landmarks.landmark:
            landmarks.extend([landmark.x, landmark.y, landmark.z])

        # Predict the pose
        landmarks = [landmarks]  # Reshape for the model
        pose_prediction = classifier.predict(landmarks)[0]
        print(landmarks)
        # Display the result
        cv2.putText(image, pose_prediction, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        print(f"Pose Prediction for {image_path}: {pose_prediction}")
    elif results.pose_landmarks == None:
        print(f"Pose Prediction for {image_path}: Tertidur")
    else:
        print(f"No landmarks detected in {image_path}")

# Load the trained classifier and MediaPipe Pose
with mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5) as pose:
    classify_image("/content/drive/My Drive/desertasi/pose_objects3/person_11.jpg", pose, clf)